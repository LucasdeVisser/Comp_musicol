---
title: "Amon Tobin: similarities and differences in music over the years"
author: "Lucas de Visser"
date: "09/02/2021"
output: 
    flexdashboard::flex_dashboard:
      storyboard: true
---

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
library(tidyverse)
library(spotifyr)
library(compmus)
library(ggplot2)
library(plotly)
library(dplyr)
library(randomForest)
library(cvms)
```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
amon_tobin <- get_artist_audio_features("3mvkWMe6swnknwscwvGCHO", include_groups = "album", dedupe_albums = TRUE)
bricolage <- amon_tobin %>% filter(album_name == "Bricolage")
permutation <- amon_tobin %>% filter(album_name == "Permutation")
supermodified <- amon_tobin %>% filter(album_name == "Supermodified")
out_from_out_where <- amon_tobin %>% filter(album_name == "Out from Out Where")
chaos_theory <- amon_tobin %>% filter(album_name == "Chaos Theory")
foley_room <- amon_tobin %>% filter(album_name == "Foley Room")
isam <- amon_tobin %>% filter(album_name == "ISAM")
sydney <- amon_tobin %>% filter(album_name == "Electronic Music for the Sydney Opera House")
handful_of_dust <- amon_tobin %>% filter(album_name == "Fear in a Handful of Dust")
time_to_run <- amon_tobin %>% filter(album_name == "Time To Run")
long_stories <- amon_tobin %>% filter(album_name == "Long Stories")
fight <- amon_tobin %>% filter(album_name == "Fight! Fight! Fight!")
world_as_we_know <- amon_tobin %>% filter(album_name == "The World As We Know It")

corpus <- amon_tobin %>%
    filter(album_name != "Dark Jovian") %>%
    filter(album_name != "Chaos Theory (Remixed) [The Soundtrack to Splinter Cell 3D]") %>%
    filter(album_name != "inFAMOUS (Original Game Soundtrack)") %>%
    filter(album_name != "Verbal Remixes & Collaborations")

corpus <- mutate(corpus, track_name = tolower(track_name))
corpus <- distinct(corpus, track_name, .keep_all= TRUE)
```

### *NEW* Can a random forest algorithm distinguish between albums?

```{r, fig.height = 8, fig.width = 10}
train <- sample(nrow(corpus), 0.7*nrow(corpus), replace = FALSE)
trainset <- corpus[train,]
testset <- corpus[-train,]

forest <- randomForest(factor(album_name) ~ danceability + energy + key + loudness + mode + speechiness + acousticness + instrumentalness + liveness + valence + tempo, data=trainset)
forest <- as.data.frame(forest$confusion)
forest$class.error <- NULL
dt2 <- forest %>%
  rownames_to_column() %>%
  gather(colname, value, -rowname)

dt2 <- dt2 %>%
  mutate(value = value/14)
ggplot(dt2, aes(x=rowname, y=colname, fill=value)) + geom_tile() + theme_classic() + theme(axis.text.x = element_text(angle = 45, hjust=1), axis.title.y = element_text(vjust = 3), axis.title.x = element_text(vjust=15)) + labs(x="Actual albums", y="Predicted albums", fill= "Percentage predicted", title="Predicting the album for each track") + scale_fill_gradient(low='#ffffff', high='#0000ff')
```

***
One of the biggest question I had about my corpus is: Are albums actually distinguishable? To answer this question, I used a random forest algorithm to predict for each track to which album it belongs. In this graph you can see the result of this process.
Along the x-axis you see the the actual albums. If you look for example at the first album 'Bricolage', you can look across the y-axis to see which albums are predicted the most for tracks from this album. In the case of 'Bricolage' the algorithm could correctly predict about half of the tracks, but this is not the case with every album. It is interesting for example that the algorithm flips the two albums 'Fear in a Handful of Dust' and 'Long Stories', and listening to them you hear that indeed they are very similar.
Overall you can conclude that the algorithm does not do very well except for a few exceptions. This may be because the sample size is very small and therefore there are lots of options for overfitting or underfitting.

### Introduction and pre-analysis of the corpus
The corpus I'm going to be inspecting is a collection of all albums from the electronic artist Amon Tobin. I chose this artist because he has produced a lot of different albums, ranging from dreamy ambient music (Fear in a Handful of Dust) to very intense beats (Fight! Fight! Fight!). There are interesting comparisons to be made in this corpus. Because his earliest album is from 1997, which is a relatively early year for electronic music, the change in music over time is an obvious comparison to make. Because the corpus consists of only albums, it is also interesting to see how and if albums differ, especially very similar albums like *Fear in a Handful of Dust* and  *Long Stories*. I expect to find a lot of differences between the ambient albums and the heavier electronic albums, and I expect certain albums to be very difficult to differentiate. A strength of the corpus is that most of the music of Amon Tobin is represented in these albums. A weakness might be that certain albums might be too similar to find any meaningful differences. If expect *Fear in a Handful of Dust* and  *Long Stories* to be too similar because they both use long dreamy chords and melodies without using drums, which might be difficult for Spotify to differentiate. An atypical track for this corpus might be ‘New York Editor’, for its jazzy drums and basslines.

***
Full albums used in the corpus:  
Bricolage (1997)  
Permutation (1998)  
Supermodified (2000)  
Out From Out Where (2002)  
Chaos Theory (2005)  
Foley Room (2007)  
ISAM (2011)  
Electronic Music for the Sydney Opera House (2017)  
Fear in a Handful of Dust (2019)  
Time To Run (2019)  
Long Stories (2019)  
Fight! Fight! Fight! (2020)  
The World As We Know It (2020)  


### Are there even large differences in Amon Tobin's tracks?

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
plot1 <- ggplot(corpus, aes(x=acousticness,y=energy, color=valence, label=track_name)) + geom_point(alpha=0.5) + geom_smooth() +ggtitle("Acousticness and Energy distribution of all tracks")
```
```{r}
ggplotly(plot1)
```


***
Here we see a lot of Amon Tobin's tracks are high in energy and low in acousticness.
An interesting find though is that the more acoustic tracks tend to be less energetic than the less acoustic tracks according to Spotify, which is odd since acoustic albums like *Time To Run* feel much more energetic than mainly electronic albums like *Fear in a Handful of Dust*. Valence seems to be about evenly spread, but the few tracks with the lowest valence tend to have very low acousticness.

### Are there clear tempo differences between albums?

#### Mean tempos between albums
```{r}
corpus %>%
  group_by(album_name) %>%
  mutate(mean_tempo = mean(tempo)) %>%
  mutate(mean_energy = mean(energy)) %>%
  ggplot(aes(x=mean_tempo, y=mean_energy)) + geom_text(aes(label=album_name, color=album_release_year),size=3) +xlim(65, 175) +scale_color_gradient(low='#00ff00', high='#0000ff') +theme_classic()
```

#### Tempo distribution of all tracks

```{r}
corpus %>%
  ggplot(aes(x=tempo)) + geom_histogram(fill='red', alpha=0.2) +theme_classic() +geom_density(aes(y=..count..*10, color='red'), size=1) + theme(legend.position = "none", axis.ticks.y = element_blank())
```

***
In the first graph you can see tempo and energy means of all Amon Tobin albums. As you expect tempo and energy seem to be correlated, as the higher the tempo the higher the energy level seems to be. You can also see that his earlier albums are clustered around 125 BPM with a high energy, whereas his later albums are much more spread out both for tempo and energy.
But the first plot only shows the means of the albums, we also want to know the general distribution of all tracks for tempo. The second plot shows just that. As you can see by the line, all of Amon Tobin's music is distribution between two general tempi. Here you can also see that most tracks have a BPM of around 160-170, whereas the first graph shows that the highest mean tempo is for 'Bricolage' which is only around 155 BPM. This indicates that in albums there are tracks with a significantly lower tempo which bring down the mean.

### A spectogram analysis of the outlier track "Big Furry Head"

#### A spectogram of the whole track

```{r}
big_furry_head <-
  get_tidy_audio_analysis("1NOIIbDFL2xRlUxZQ91V8W") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

big_furry_head %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() + labs(title="Spectogram of 'Big Furry Head'")
```

####  The first 50 seconds of 'Big Furry Head' shows the difference percussion makes

```{r}
big_furry_head %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() + xlim(0, 50) + labs(title="First 50 seconds of 'Big Furry Head'")
```

***
Here you see the spectogram of the track 'Big Furry Head'. This track was an outlier because it has high energy while being somewhere in the middle on acousticness (see the previous page). The spectogram does not immediately show any inconsistensies. It is interesting that you can cleary see that the majority of the track involves percussion except for the beginning and end, because percussive instruments produce noise which consists of many different frequencies. The next page shows a closer look to see the difference in bits with percussion and without.

The first half of this clip shows very distinct notes in the spectogram. Interesting is how it interprets a portamento from B to Bb around the 4 second mark. At the 13 second mark new layers of instruments are slowly introduced, and at around 27 seconds in you can clearly see the point where the drums start playing. From there on the spectogram becomes very chaotic, as expected.

### Do his albums differ in terms of high level Spotify features?

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
mean_bricolage <- mean(bricolage$energy)
mean_permutation <- mean(permutation$energy)
mean_supermodified <- mean(supermodified$energy)
mean_out_from_out_where <- mean(out_from_out_where$energy)
mean_chaos_theory <- mean(chaos_theory$energy)
mean_foley_room <- mean(foley_room$energy)
mean_isam <- mean(isam$energy)
mean_sydney <- mean(sydney$energy)
mean_handful_of_dust <- mean(handful_of_dust$energy)
mean_time_to_run <- mean(time_to_run$energy)
mean_long_stories <- mean(long_stories$energy)
mean_fight <- mean(fight$energy)
mean_world_as_we_know <- mean(world_as_we_know$energy)

corpus <- corpus %>%
  group_by(album_name) %>%
  mutate(mean_energy = mean(energy)) %>%
  mutate(mean_valence = mean(valence)) %>%
  mutate(mean_danceability = mean(danceability)) %>%
  mutate(mean_acousticness = mean(acousticness))


plot <- ggplot(corpus, aes(x=mean_valence, y=mean_energy)) + geom_text(aes(label=album_name, color=mean_danceability), size=3) + theme_classic() + ggtitle("Mean Valence and Energy of all albums") +xlim(-0.2, 0.7) +ylim(0.33, 0.85)
```

```{r}
ggplotly(plot)
```


***
Here you can see there are clear differences between albums. There is also an interesting relationship between energy, valence and danceability, namely albums with high valence tend to have high energy as well as high danceability. Another thing to note is that Amon Tobin's albums are relatively low in valence, while energy seems to vary much more. Mouse over the plot to see the specific values.

### Taking a look at 'Toys' through cepstrograms

#### Cepstrogram of 'Toys' based on sections

```{r, cache=TRUE}
toys <-
  get_tidy_audio_analysis("6DkRA7SFuraU8wlChIDt9c") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

toys %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```


#### Cepstogram of 'Toys' based on beats

```{r, cache=TRUE}
toys <-
  get_tidy_audio_analysis("6DkRA7SFuraU8wlChIDt9c") %>% # Change URI.
  compmus_align(beats, segments) %>%                     # Change `bars`
  select(beats) %>%                                      #   in all three
  unnest(beats) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

toys %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

***
These are cepstograms of a typical Amon Tobin track called "Toys". As you can see in the cepstograms, which is also very audible in the track, almost exactly halfway the track it changes in a big way. You can see that because the first half the third coefficient is most present, while in the second half the second coefficient is mostly present.

### SSM of the track 'Reanimator'

```{r, cache=TRUE}
reanimator <-
  get_tidy_audio_analysis("3IIRFqcAthIwk670PebTgZ") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

reanimator %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title="SSM based on timbre of the track 'Reanimator'")

```

***
This is a self-similarity matrix for timbre of the track 'Reanimator', since this track is a very typical track of Amon Tobin according to the Spotify features. There are dark patches here and there which indicate similar timbre throughout the track. Interesting points are the yellow line at around 185 seconds which indicates the moment the heavy drums kick in and the cluster of yellow lines at around 250 seconds which indicate a transitional moment in the track.

### tempo and loudness of albums in chronological order

```{r}
corpus %>%
  mutate(album_name = factor(album_name, levels=c("Bricolage", "Permutation", "Supermodified", "Out from Out Where", "Chaos Theory", "Foley Room", "ISAM", "Electronic Music for the Sydney Opera House", "Long Stories", "Time To Run", "Fear in a Handful of Dust", "The World As We Know It", "Fight! Fight! Fight!"))) %>%
  group_by(album_name) %>%
  mutate(mean_loudness = mean(loudness)) %>%
  ggplot(aes(x=album_name, y=tempo, fill=mean_loudness)) + geom_boxplot() + theme_classic() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(x="")  + scale_fill_gradient(low = "#ffdbdb", high = "#ff6363")
```

***
Here you can see the tempo and loudness of all the albums in chronological order. If you look at tempo you see a clear progression in albums from 1997 till 2020, you can sort of draw a curve for tempo in time. It is also interesting that later albums differ much more in loudness than earlier albums. The deviation of tempo (indicated by the boxes) is overall also much higher in later albums. This indicated a clear change in music.

### Lets look at the harmonic progression over time

```{r, echo=FALSE, results='hide', warning=FALSE}
corpus <- mutate(corpus, after_2007 = album_release_year > 2007)

corpus %>%
  ggplot(aes(x=key_name, fill=mode_name)) + geom_bar() + theme_classic() + facet_wrap( ~after_2007, labeller=label_both)

```

***
I want to look at how Amon Tobin's music changed harmonically over the years. To avoid cluttering I've split all his tracks around the midpoint of his career, 2007. In this graph you can see the distribution of keys he used in his tracks, as well as the distribution of major and minor tracks. The most interesting find in this graph is the key C#. After 2007 there are more tracks produced in C# minor, but significantly less in C# major. After investigating further, I noticed most of the tracks in C# minor before 2007 were from the album 'Supermodified'. In the next page I take a closer look at one of those tracks for any interesting harmonic information.


### Taking a closer look at the harmonics of multiple C# minor tracks from before 2000

#### Keygram of the track 'Slowly'

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```
```{r}
slowly <-
  get_tidy_audio_analysis("15J6PrzKaLtvw0dBr9sq72") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

slowly %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_x_continuous(breaks=round(seq(0, 337, by = 50),1)) +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "Key", title="")
```

#### Keygram of the track 'Get Your Snack On'

```{r, cache=TRUE}
snack <-
  get_tidy_audio_analysis("14BIjb7JQJzUPBE7PxLV25") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

snack %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_x_continuous(breaks=round(seq(0, 337, by = 50),1)) +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "Key")
```


***
These are two tracks from before 2007 which Spotify labeled as C# minor. As you can see, while the harmonic structure of both tracks are very much visible looking at vertical lines, the keygrams do not settle on one key for both tracks. If you listen to the tracks, you can hear that they do not rely on harmony too much. You can make out melody and a chord here and there, but rhythm takes center stage in these tracks. I do not know why Spotify labels both these tracks (and other aharmonic tracks from the same album) as being in C# minor. I would even say that 'Slowly' is more suited in B major, as throughout the track you constantly hear an F# followed by a B chord. That corresponds to V-I if the track is in B major, which makes it very musically suitable for B major.